{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"top\"></div> \n",
    "# Table of contents\n",
    "* <a href='#Submission-instructions'>Submission instructions</a>\n",
    "* <a href=\"#A-short-introduction-to-LaTeX\">A short introduction to LaTeX</a>\n",
    "* <a href=\"#Some-useful-numpy-functions\">Some useful numpy functions</a>\n",
    "* <a href=\"#The-start-of-this-homework\">The start of this homework</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission instructions\n",
    "Submit your .ipynb file to **jsilva@cs.unc.edu**\n",
    "\n",
    "Give us your name and PID. List the name of your colaborator. \n",
    "\n",
    "```\n",
    "To: jsilva@cs.unc.edu\n",
    "Cc: poirson@cs.unc.edu, svetak.sundhar@gmail.com\n",
    "From: Super Student\n",
    "Subject: HW1 submission\n",
    "\n",
    "\n",
    "First Name: Super\n",
    "Last Name: Student\n",
    "PID: 11111111\n",
    "\n",
    "Colaborated with: \n",
    "First Name: Another\n",
    "Last Name: Student\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A short introduction to LaTeX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "$ \\LaTeX $ is a markup language to typeset documents. You can use it to express math compactly and make the layout of your documents beautiful. For the purpose of this class, we focus on the first piece, that is writing mathematical formulations. Jupyter implements a subset of $\\LaTeX$. Therefore, you can use $ \\LaTeX $ to answers the problems in the assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two modes in latex that can typeset the formulations\n",
    "1. Inline mode, start with an \\$, end with an \\$ (\\$...\\$). E.g. $a + b = \\frac{1}{3}$\n",
    "2. Display mode, start with two \\$\\$, end with two \\$\\$ (\\$\\$...\\$\\$). E.g. $$a+b=\\frac{1}{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Maths\n",
    "1. It is straight-forward for basic arithmetic operations. E.g. $+, - * /, a^b, a_b$.\n",
    "2. $ \\LaTeX$ already defined many useful symbols, macros, (or functions) to typeset the formulations. They start with \\, such as \\LaTeX is for the latex symbol. In some typeset functions you can give them parameters. E.g. \\frac{1}{3} typesets one over three, where the thing within the first {} is nominator, and the thing within the second {} is denominator. {} also helps group thing within it together. Consider the difference between a\\_b+1 ($a_b+1$) and a\\_{b+1} ($a_{b+1}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful symbols and functions\n",
    "1. fraction, \\frac{1}{3}. ($\\frac{1}{3}$)\n",
    "2. partial derivative, \\partial. ($\\partial$), Combined with 1), we have \\frac{\\partial f}{\\partial x}. ($\\frac{\\partial f}{\\partial x}$)\n",
    "3. summation, \\sum\\_{i=1}^{N}. ($\\sum_{i=1}^{N}$)\n",
    "4. products, \\prod\\_{i=1}^{N}. ($\\prod_{i=1}^{N}$)\n",
    "5. indexing, w\\_{i, j}. ($w_{i, j}$)\n",
    "6. frequently used Greek letters \\alpha, \\beta, \\gamma. ($\\alpha, \\beta, \\gamma$)\n",
    "7. gradient notation \\nabla. ($\\nabla$)\n",
    "8. vector forms $\\text{\\\\begin{bmatrix} x_{i, 1} \\\\ \\vdots \\\\ x_{i, p+1}  \\\\end{bmatrix}}$. ($\\begin{bmatrix} x_{i, 1} \\\\ \\vdots \\\\ x_{i, p+1} \\end{bmatrix}$) <br \\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some useful numpy functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People usualy import numpy as the follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we introduce some useful numpy functions that you might use in this homework.\n",
    "* zeros <br \\>\n",
    "zeros generates a multi-dimensional array that contains all zeros. <br \\>\n",
    "    * Example: <br \\>\n",
    "    ** zeros( (3, 2) ) ** generates a 2d array of size 3\\*2 (three rows and 2 columns) that contains zeros in all entries. <br \\>\n",
    "    ** zeros( (3, 2, 4) )** generates a 3d array of size 3\\*2\\*4 that also contains zero in all entries.\n",
    "* ones <br \\>\n",
    "Similar to zeros, ones generates a multi-dimensional array that contains all ones. <br \\>\n",
    "* exp <br \\>\n",
    "exp takes exponential on each entry of the input. <br \\>\n",
    "    * Example: <br \\>\n",
    "    ** exp(3) ** computes $ e^3 $. <br \\>\n",
    "    ** exp( [1, 2, 3] ) ** computes $[ e^1, e^2, e^3]$.\n",
    "* log <br \\>\n",
    "Similar to exp, log takes log on each entry of the input. Since log function is not defined on the values $<= 0$, if the input of log is like that, it will output nan or inf defined in numpy. <br \\>\n",
    "* sum <br \\>\n",
    "sum takes sum over an axis of the input array. <br \\>\n",
    "    * Example: please see the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input array is a 3*3 matrix, values: \n",
      " [[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "result 1 is  [ 9 12 15]\n",
      "result 2 is  [ 3 12 21]\n"
     ]
    }
   ],
   "source": [
    "matrixA = np.arange(9).reshape(3, 3)\n",
    "print( 'input array is a 3*3 matrix, values: \\n', matrixA )\n",
    "result1 = np.sum(matrixA, axis = 0)\n",
    "result2 = np.sum(matrixA, axis = 1)\n",
    "print( 'result 1 is ', result1 )\n",
    "print( 'result 2 is ', result2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dot <br \\>\n",
    "do dot-product of the two inputs (if they are vectors), or do matrix multiplication of the two inputs (if they are 2d arrays). In numpy if A and B are both arrays, A\\*B computes the element-wise multiplication, not matrix multiplication. To use dot, the dimensions of the two inputs must be valid. <br \\>\n",
    "    * Example: please see the following code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecotr 1 is a length-3 vector, values:  [1 2 3]\n",
      "vecotr 2 is a length-3 vector, values:  [1 2 1]\n",
      "dot product of vecotr 1 and 2 is 8\n",
      "dot product of vecotr 1 and 3 generates error\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (3,) and (4,) not aligned: 3 (dim 0) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-787e21c58338>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvector3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'dot product of vecotr 1 and 3 generates error'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (3,) and (4,) not aligned: 3 (dim 0) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "#dot product examples\n",
    "vector1 = np.array( [1, 2, 3] )\n",
    "vector2 = np.array( [1, 2, 1] )\n",
    "print( 'vecotr 1 is a length-3 vector, values: ', vector1 )\n",
    "print( 'vecotr 2 is a length-3 vector, values: ', vector2 )\n",
    "print( 'dot product of vecotr 1 and 2 is', np.dot(vector1, vector2) )\n",
    "vector3 = np.array( [1, 2, 1, 2])\n",
    "print( 'dot product of vecotr 1 and 3 generates error' )\n",
    "np.dot(vector1, vector3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix1 is a 2*3 matrix, values: \n",
      "  [[0 1 2]\n",
      " [3 4 5]]\n",
      "matrix2 is a 3*1 matrix, values: \n",
      "  [[1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "matrix1 multiplies matrix2 is a 2*1 matrix: \n",
      "  [[ 3.]\n",
      " [12.]]\n"
     ]
    }
   ],
   "source": [
    "#matrix multiplication examples\n",
    "matrix1 = np.arange(6).reshape(2, 3)\n",
    "matrix2 = np.ones(((3,1)))\n",
    "print( 'matrix1 is a 2*3 matrix, values: \\n ', matrix1 )\n",
    "print( 'matrix2 is a 3*1 matrix, values: \\n ', matrix2 )\n",
    "print( 'matrix1 multiplies matrix2 is a 2*1 matrix: \\n ', np.dot(matrix1, matrix2) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* T <br \\>\n",
    "[numpy matrix variable].T, takes transpose of the input matrix variable.\n",
    "    * Example: please see the following code cell <br \\>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix dimension is (4, 3)\n",
      "matrix dimension after transpose is (3, 4)\n"
     ]
    }
   ],
   "source": [
    "matrix1 = np.ones( (4, 3) )\n",
    "print( 'matrix dimension is',  matrix1.shape )\n",
    "print( 'matrix dimension after transpose is', matrix1.T.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The start of this homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import plotting utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should take at most 30 seconds\n",
      "Time elapsed (seconds): 0.0003590583801269531\n"
     ]
    }
   ],
   "source": [
    "#download data\n",
    "import time\n",
    "import urllib\n",
    "import os.path\n",
    "import sys\n",
    "versionName = sys.version_info\n",
    "if versionName[0] == 2:\n",
    "    import urllib as U\n",
    "elif versionName[0] == 3:\n",
    "    import urllib.request as U\n",
    "start = time.time()\n",
    "print(\"Should take at most 30 seconds\")\n",
    "if not os.path.isfile('train_data.pgz'):\n",
    "    U.urlretrieve(\"https://sakai.unc.edu/access/content/group/c4f84923-328b-429b-a8dc-a340b0284e41/HW1/train_data.pgz\", \"train_data.pgz\")\n",
    "if not os.path.isfile('test_data.pgz'):\n",
    "    U.urlretrieve(\"https://sakai.unc.edu/access/content/group/c4f84923-328b-429b-a8dc-a340b0284e41/HW1/test_data.pgz\", \"test_data.pgz\")\n",
    "if not os.path.isfile('vocab_list.pgz'):\n",
    "    U.urlretrieve( \"https://sakai.unc.edu/access/content/group/c4f84923-328b-429b-a8dc-a340b0284e41/HW1/vocab_list.pgz\", \"vocab_list.pgz\" );\n",
    "end = time.time()\n",
    "print(\"Time elapsed (seconds):\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should take about 15 seconds\n",
      "Time elapsed (seconds): 6.721787214279175\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "    kwargs = {}\n",
    "except:\n",
    "    import _pickle as pickle\n",
    "    kwargs = {'encoding':'bytes'}\n",
    "    \n",
    "import gzip\n",
    "import numpy as np\n",
    "start = time.time()\n",
    "print(\"Should take about 15 seconds\")\n",
    "train_data, train_label = pickle.load( gzip.open( \"train_data.pgz\", \"rb\" ), **kwargs )\n",
    "train_label = np.asarray(train_label)\n",
    "test_data = pickle.load( gzip.open( \"test_data.pgz\", \"rb\" ),**kwargs )\n",
    "vocab_list = pickle.load( gzip.open( \"vocab_list.pgz\", \"rb\" ),**kwargs )\n",
    "end = time.time()\n",
    "print(\"Time elapsed (seconds):\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'absolutely', 'across', 'act', 'acted', 'acting', 'action', 'actor', 'actors', 'actress', 'actual', 'actually', 'add', 'admit', 'adult', 'adventure', 'age', 'ago', 'agree', 'air', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'amazing', 'america', 'american', 'among', 'amusing', 'animated', 'animation', 'annoying', 'another', 'anyone', 'anything', 'anyway', 'apart', 'apparently', 'appear', 'appears', 'appreciate', 'around', 'art', 'ask', 'atmosphere', 'attempt', 'attempts', 'attention', 'audience', 'average', 'avoid', 'away', 'awful', 'baby', 'back', 'background', 'bad', 'badly', 'band', 'based', 'basic', 'basically', 'battle', 'beautiful', 'beauty', 'became', 'become', 'becomes', 'begin', 'beginning', 'begins', 'behind', 'believable', 'believe', 'ben', 'best', 'better', 'beyond', 'big', 'biggest', 'bill', 'bit', 'bizarre', 'black', 'blood', 'body', 'book', 'books', 'bored', 'boring', 'box', 'boy', 'boys', 'break', 'brilliant', 'bring', 'brings', 'british', 'brother', 'brothers', 'brought', 'budget', 'bunch', 'business', 'buy', 'call', 'called', 'came', 'camera', 'cannot', 'car', 'care', 'career', 'cartoon', 'case', 'cast', 'casting', 'cat', 'caught', 'cause', 'century', 'certain', 'certainly', 'chance', 'change', 'character', 'characters', 'cheap', 'check', 'cheesy', 'child', 'children', 'choice', 'christmas', 'cinema', 'cinematography', 'city', 'class', 'classic', 'clear', 'clearly', 'clever', 'clich', 'close', 'co', 'cold', 'come', 'comedy', 'comes', 'comic', 'coming', 'comment', 'comments', 'common', 'company', 'compared', 'complete', 'completely', 'concept', 'consider', 'considering', 'control', 'convincing', 'cool', 'cop', 'copy', 'could', 'country', 'couple', 'course', 'cover', 'crap', 'crazy', 'create', 'created', 'credit', 'credits', 'creepy', 'crew', 'crime', 'cut', 'cute', 'dance', 'dancing', 'dark', 'daughter', 'david', 'day', 'days', 'de', 'dead', 'deal', 'death', 'decent', 'decided', 'decides', 'deep', 'definitely', 'depth', 'deserves', 'despite', 'development', 'dialog', 'dialogue', 'die', 'died', 'different', 'difficult', 'directed', 'directing', 'direction', 'director', 'directors', 'disappointed', 'disney', 'doctor', 'documentary', 'dog', 'done', 'doubt', 'dr', 'drama', 'dramatic', 'dream', 'due', 'dull', 'dumb', 'dvd', 'earlier', 'early', 'earth', 'easily', 'easy', 'editing', 'effect', 'effective', 'effects', 'effort', 'either', 'elements', 'else', 'emotional', 'end', 'ended', 'ending', 'ends', 'english', 'enjoy', 'enjoyable', 'enjoyed', 'enough', 'entertaining', 'entertainment', 'entire', 'entirely', 'episode', 'episodes', 'era', 'escape', 'especially', 'etc', 'even', 'events', 'eventually', 'ever', 'every', 'everyone', 'everything', 'evil', 'exactly', 'example', 'excellent', 'except', 'exciting', 'expect', 'expected', 'expecting', 'experience', 'extremely', 'eye', 'eyes', 'face', 'fact', 'fails', 'fairly', 'fall', 'falls', 'familiar', 'family', 'famous', 'fan', 'fans', 'fantastic', 'fantasy', 'far', 'fast', 'father', 'favorite', 'fear', 'feature', 'features', 'feel', 'feeling', 'feels', 'felt', 'female', 'fi', 'fight', 'fighting', 'figure', 'filled', 'film', 'filmed', 'filmmakers', 'films', 'final', 'finally', 'find', 'finds', 'fine', 'fire', 'first', 'five', 'flat', 'flick', 'focus', 'follow', 'following', 'follows', 'footage', 'force', 'forced', 'forget', 'form', 'former', 'forward', 'found', 'four', 'free', 'french', 'friend', 'friends', 'front', 'full', 'fun', 'funny', 'future', 'game', 'gave', 'gay', 'general', 'genre', 'george', 'german', 'get', 'gets', 'getting', 'girl', 'girlfriend', 'girls', 'give', 'given', 'gives', 'giving', 'go', 'god', 'goes', 'going', 'gone', 'good', 'gore', 'got', 'great', 'greatest', 'group', 'guess', 'gun', 'guy', 'guys', 'hair', 'half', 'hand', 'hands', 'happen', 'happened', 'happens', 'happy', 'hard', 'hardly', 'hate', 'head', 'hear', 'heard', 'heart', 'hell', 'help', 'hero', 'high', 'highly', 'hilarious', 'history', 'hit', 'hold', 'hollywood', 'home', 'hope', 'horrible', 'horror', 'hot', 'hour', 'hours', 'house', 'however', 'huge', 'human', 'humor', 'husband', 'idea', 'ideas', 'imagine', 'imdb', 'important', 'impressive', 'including', 'incredible', 'incredibly', 'indeed', 'inside', 'instead', 'intelligent', 'interest', 'interested', 'interesting', 'involved', 'island', 'italian', 'jack', 'james', 'jane', 'japanese', 'job', 'joe', 'john', 'joke', 'jokes', 'keep', 'keeps', 'kept', 'kid', 'kids', 'kill', 'killed', 'killer', 'killing', 'kills', 'kind', 'king', 'knew', 'know', 'known', 'knows', 'la', 'lack', 'lady', 'lame', 'language', 'large', 'last', 'late', 'later', 'laugh', 'laughing', 'laughs', 'law', 'lead', 'leading', 'leads', 'learn', 'least', 'leave', 'leaves', 'lee', 'left', 'less', 'let', 'level', 'life', 'light', 'like', 'liked', 'line', 'lines', 'list', 'little', 'live', 'lives', 'living', 'local', 'long', 'look', 'looked', 'looking', 'looks', 'lost', 'lot', 'lots', 'love', 'loved', 'low', 'mad', 'made', 'main', 'major', 'make', 'makes', 'making', 'male', 'man', 'manages', 'many', 'mark', 'married', 'mary', 'masterpiece', 'match', 'material', 'matter', 'may', 'maybe', 'mean', 'means', 'meant', 'meet', 'meets', 'members', 'memorable', 'men', 'mention', 'mentioned', 'mess', 'message', 'michael', 'middle', 'might', 'mind', 'minute', 'minutes', 'miss', 'missed', 'missing', 'modern', 'moment', 'moments', 'money', 'monster', 'mostly', 'mother', 'move', 'moves', 'movie', 'movies', 'moving', 'mr', 'much', 'murder', 'music', 'musical', 'must', 'mystery', 'name', 'named', 'nature', 'near', 'nearly', 'need', 'needed', 'needs', 'neither', 'never', 'new', 'next', 'nice', 'night', 'non', 'none', 'note', 'nothing', 'novel', 'nudity', 'number', 'obvious', 'obviously', 'odd', 'office', 'often', 'oh', 'ok', 'okay', 'old', 'older', 'one', 'ones', 'open', 'opening', 'opinion', 'order', 'original', 'oscar', 'others', 'otherwise', 'outside', 'overall', 'pace', 'parents', 'part', 'particular', 'particularly', 'parts', 'party', 'past', 'paul', 'pay', 'people', 'perfect', 'perfectly', 'performance', 'performances', 'perhaps', 'period', 'person', 'personal', 'peter', 'picture', 'piece', 'place', 'plain', 'planet', 'play', 'played', 'playing', 'plays', 'please', 'plenty', 'plot', 'plus', 'point', 'pointless', 'points', 'police', 'political', 'poor', 'poorly', 'popular', 'portrayal', 'portrayed', 'positive', 'possible', 'possibly', 'potential', 'power', 'powerful', 'predictable', 'premise', 'present', 'pretty', 'previous', 'probably', 'problem', 'problems', 'produced', 'production', 'public', 'pure', 'put', 'quality', 'question', 'quickly', 'quite', 'rate', 'rated', 'rather', 'rating', 'read', 'reading', 'real', 'realistic', 'reality', 'realize', 'really', 'reason', 'reasons', 'recent', 'recently', 'recommend', 'red', 'relationship', 'release', 'released', 'remake', 'remember', 'rent', 'respect', 'rest', 'result', 'return', 'revenge', 'review', 'reviews', 'rich', 'richard', 'ridiculous', 'right', 'robert', 'rock', 'role', 'roles', 'romance', 'romantic', 'room', 'run', 'running', 'runs', 'sad', 'sadly', 'said', 'save', 'saw', 'say', 'saying', 'says', 'scary', 'scene', 'scenes', 'school', 'sci', 'science', 'score', 'scott', 'screen', 'screenplay', 'script', 'season', 'second', 'secret', 'see', 'seeing', 'seem', 'seemed', 'seems', 'seen', 'sees', 'self', 'sense', 'sequel', 'sequence', 'sequences', 'series', 'serious', 'seriously', 'set', 'sets', 'setting', 'several', 'sex', 'sexual', 'shame', 'short', 'shot', 'shots', 'show', 'showing', 'shown', 'shows', 'side', 'silly', 'similar', 'simple', 'simply', 'since', 'singing', 'single', 'sister', 'sit', 'situation', 'slightly', 'slow', 'small', 'social', 'society', 'solid', 'somehow', 'someone', 'something', 'sometimes', 'somewhat', 'son', 'song', 'songs', 'soon', 'sorry', 'sort', 'sound', 'sounds', 'soundtrack', 'space', 'speak', 'special', 'spend', 'spent', 'spirit', 'spoilers', 'stage', 'stand', 'star', 'stars', 'start', 'started', 'starts', 'state', 'stay', 'still', 'stop', 'store', 'stories', 'story', 'storyline', 'straight', 'strange', 'street', 'strong', 'studio', 'stuff', 'stupid', 'style', 'subject', 'success', 'successful', 'suddenly', 'super', 'superb', 'supporting', 'supposed', 'sure', 'surprise', 'surprised', 'suspense', 'sweet', 'take', 'taken', 'takes', 'taking', 'tale', 'talent', 'talented', 'talk', 'talking', 'team', 'television', 'tell', 'telling', 'tells', 'ten', 'tension', 'terrible', 'th', 'theater', 'theme', 'thing', 'things', 'think', 'thinking', 'third', 'though', 'thought', 'three', 'thriller', 'throughout', 'time', 'times', 'title', 'today', 'together', 'told', 'tom', 'tone', 'tony', 'took', 'top', 'total', 'totally', 'towards', 'town', 'trash', 'tried', 'tries', 'trouble', 'true', 'truly', 'truth', 'try', 'trying', 'turn', 'turned', 'turns', 'tv', 'twist', 'two', 'type', 'typical', 'ultimately', 'understand', 'unfortunately', 'unique', 'unless', 'unlike', 'upon', 'us', 'use', 'used', 'uses', 'using', 'usual', 'usually', 'value', 'various', 'version', 'video', 'view', 'viewer', 'viewers', 'viewing', 'villain', 'violence', 'violent', 'visual', 'voice', 'wait', 'waiting', 'walk', 'want', 'wanted', 'wants', 'war', 'waste', 'wasted', 'watch', 'watched', 'watching', 'water', 'way', 'ways', 'weak', 'weird', 'well', 'went', 'western', 'whatever', 'whether', 'white', 'whole', 'whose', 'wife', 'william', 'wish', 'within', 'without', 'woman', 'women', 'wonder', 'wonderful', 'word', 'words', 'work', 'worked', 'working', 'works', 'world', 'worse', 'worst', 'worth', 'would', 'write', 'writer', 'writers', 'writing', 'written', 'wrong', 'wrote', 'year', 'years', 'yes', 'yet', 'york', 'young', 'younger', 'zombie', 'zombies']\n"
     ]
    }
   ],
   "source": [
    "#Consider using small set of the data\n",
    "trainData = train_data[:10000, :]\n",
    "validData = train_data[10000:15000, :]\n",
    "trainLabel = train_label[:10000]\n",
    "validLabel = train_label[10000:15000]\n",
    "testData = test_data[:10000, :]\n",
    "print( vocab_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.01049613e-15, -5.65727465e-16,  2.07511563e-15, -1.25034871e-15,\n",
       "        8.93827234e-16,  2.09658957e-16,  1.24238841e-15,  1.42255097e-16,\n",
       "        1.64055436e-15, -9.47040224e-16,  2.49471777e-15, -2.77537993e-16,\n",
       "       -1.35806033e-15, -2.28569386e-16, -4.80685491e-16,  4.10660395e-17,\n",
       "       -1.47469592e-15, -2.29052333e-16,  1.79992687e-15,  5.72459857e-16,\n",
       "       -7.98441313e-16, -7.43938244e-17, -1.37430067e-15, -4.51683135e-16,\n",
       "        5.87072613e-16, -1.25504496e-15,  7.40705275e-16, -1.24832367e-15,\n",
       "       -2.98550518e-15, -2.53230104e-15, -2.07554862e-15, -1.01518793e-17,\n",
       "        5.15988363e-16, -3.17301740e-16, -1.22530652e-15,  1.63173031e-15,\n",
       "       -1.02405640e-15, -4.67292871e-16, -3.91819910e-17, -1.19720900e-15,\n",
       "        2.47845300e-15, -1.31523681e-16,  6.25703933e-16,  2.51556553e-16,\n",
       "        1.78223658e-15, -1.40591760e-15,  7.31237293e-16, -8.80038264e-16,\n",
       "       -8.96323016e-16,  7.37727657e-16,  8.86091200e-16, -1.26235244e-15,\n",
       "       -4.65816274e-16,  7.35764782e-16, -9.39963662e-16,  3.27660121e-16,\n",
       "       -7.29555305e-16, -7.02549130e-17,  7.68816122e-16,  1.80150561e-15,\n",
       "       -1.61279656e-15,  8.43154435e-16,  1.01290087e-16, -8.83166873e-16,\n",
       "        1.22529320e-15, -1.20171983e-15, -1.47377222e-15, -1.69755321e-16,\n",
       "       -1.13765664e-15, -3.42539108e-15,  1.81495929e-15,  1.02292397e-15,\n",
       "       -5.55755442e-17, -1.03895559e-15, -7.87481191e-17,  7.18989313e-16,\n",
       "        9.81437154e-19,  9.75383108e-16, -7.74407205e-16, -8.23574542e-16,\n",
       "       -1.01402442e-15,  3.20503624e-16, -4.79116746e-16, -1.03097531e-16,\n",
       "        1.40933487e-15, -3.94573263e-16,  4.78002082e-16, -7.11430914e-18,\n",
       "       -2.43287612e-16,  2.28898456e-15, -1.43313361e-15,  1.46509249e-15,\n",
       "       -1.98862482e-15, -1.30762068e-17, -6.47351062e-16,  1.45788936e-16,\n",
       "        1.21128219e-15,  2.37354580e-16,  1.76745174e-15, -1.93071559e-15,\n",
       "        9.48741086e-16,  4.07502920e-16, -9.38817912e-16, -8.92610430e-16,\n",
       "        3.25179883e-16,  2.36988873e-15,  2.25215402e-16,  7.93161092e-16,\n",
       "       -2.62359023e-16, -1.17639232e-15,  5.67770275e-16, -6.75564049e-16,\n",
       "       -1.60262248e-15, -1.10456089e-15, -1.80880422e-15, -1.84725568e-16,\n",
       "        5.26514388e-16, -7.59681207e-17, -1.07724940e-15,  3.15438786e-16,\n",
       "        6.91339208e-16, -8.49844639e-16, -1.53317359e-16, -7.82891529e-16,\n",
       "        2.16185958e-15,  8.82476314e-16,  9.50794998e-17, -6.24167384e-16,\n",
       "        6.38027409e-16, -2.83209012e-16,  5.67299541e-16,  2.11542561e-15,\n",
       "       -1.32543532e-15,  1.21730181e-15, -1.62287073e-15,  2.84945401e-16,\n",
       "       -3.60791397e-16,  3.29047900e-17,  1.50068624e-15,  7.86022358e-16,\n",
       "        1.80736537e-15,  9.44642142e-16, -1.51694879e-15,  5.72326631e-16,\n",
       "        8.80964190e-16, -4.40654180e-16,  7.95490340e-16, -1.13306697e-15,\n",
       "        7.62645502e-16, -3.13096216e-16,  6.70317135e-16, -4.00874889e-16,\n",
       "        2.14348317e-15, -6.71880329e-16, -1.02675646e-16,  7.32527372e-16,\n",
       "       -1.14027232e-15,  4.82573981e-16,  1.19176446e-15, -6.91844360e-16,\n",
       "        3.82704979e-16, -4.89652763e-17, -1.51304747e-15,  2.28078889e-15,\n",
       "       -7.22819582e-16,  2.17898366e-15, -3.08735260e-16, -2.12693863e-15,\n",
       "        1.62317271e-15, -8.82129925e-16, -4.35361081e-15,  8.50559623e-16,\n",
       "       -2.59939625e-15,  7.69695419e-17,  7.42497175e-16, -3.76860765e-16,\n",
       "        5.08189046e-16,  3.69073661e-16, -3.37663231e-17, -3.99542621e-16,\n",
       "       -9.36388744e-16,  1.39301903e-16,  3.04852144e-15, -1.93018268e-15,\n",
       "       -4.64883687e-16, -6.18853857e-16, -1.20092269e-15,  9.00102215e-17,\n",
       "        2.85445001e-16,  6.46807052e-16, -2.77200485e-16,  3.23784111e-15,\n",
       "        1.80306992e-15, -9.08850772e-17, -2.87099011e-15, -1.35207401e-15,\n",
       "       -2.16898277e-15,  3.86011223e-16,  4.66371386e-16, -9.33495503e-16,\n",
       "        2.83064683e-16,  5.12265785e-16,  1.83225879e-15, -7.93938248e-16,\n",
       "        8.40549852e-17, -1.72857062e-15, -3.32640582e-16,  1.23729693e-15,\n",
       "        1.02066799e-15, -1.61660907e-15,  2.23810970e-15, -6.08701978e-16,\n",
       "        8.40421066e-16,  5.26723110e-16,  1.37731160e-15,  5.46973578e-16,\n",
       "       -6.82238710e-16, -1.51072599e-15, -2.85594881e-16,  1.84298299e-15,\n",
       "        5.03018738e-16, -1.25950361e-15, -2.99009706e-16,  1.03612785e-15,\n",
       "        6.08171291e-16, -1.97274419e-15, -1.04659392e-15, -6.35391739e-16,\n",
       "       -1.13860921e-15, -8.10260747e-16,  2.64699374e-16, -5.95927752e-16,\n",
       "        3.98461264e-16, -1.64336322e-15, -1.76401782e-15,  1.05438103e-15,\n",
       "        3.07598391e-17, -5.64719382e-16, -1.31222144e-15,  1.31936906e-15,\n",
       "       -1.87171167e-15, -4.21866986e-16, -1.16513688e-15,  3.51972229e-15,\n",
       "        1.25079502e-15,  6.43143316e-16, -2.81463741e-16,  7.26956273e-16,\n",
       "        9.42057543e-16,  9.05937547e-16,  2.52986521e-16,  1.69237069e-15,\n",
       "        9.67879110e-16,  1.90845117e-15,  1.70089054e-15,  5.67528247e-16,\n",
       "        1.29566802e-15, -8.01847477e-17, -9.83446657e-16,  9.03590536e-16,\n",
       "        1.78297155e-15,  2.50878207e-16, -1.36745726e-15,  7.34110550e-16,\n",
       "       -3.44035911e-17, -5.54194468e-16,  3.23374660e-16,  2.30283792e-15,\n",
       "       -9.75100001e-16, -5.55875346e-16, -8.49529336e-16, -2.10313988e-16,\n",
       "       -2.47004639e-16, -1.34216194e-15,  8.74256223e-16,  2.36015651e-16,\n",
       "       -8.22979462e-16, -4.06519263e-16, -1.96220817e-15,  1.08080211e-16,\n",
       "        1.51324286e-15,  9.38553679e-16, -3.60014241e-16, -5.10065323e-16,\n",
       "       -2.37961872e-15, -1.14221965e-15,  1.04619202e-15, -1.28068001e-15,\n",
       "        2.27775576e-16, -1.63726810e-15, -1.45277346e-15, -2.53934651e-16,\n",
       "        1.91931804e-15, -2.64466227e-16, -2.42852405e-16, -1.76143544e-16,\n",
       "       -1.45716217e-15,  5.09858822e-17,  1.01081810e-15, -1.37288625e-15,\n",
       "       -4.04625222e-16, -4.26707558e-16, -4.44015935e-16, -6.88258339e-16,\n",
       "        3.20263815e-16,  2.27871055e-16, -3.40202755e-15,  3.42141870e-16,\n",
       "       -2.42306175e-16, -8.56514859e-17,  1.62279967e-15, -1.16465282e-15,\n",
       "        5.42597078e-16, -9.43749523e-16,  7.75202125e-17,  8.09790013e-16,\n",
       "       -1.43447920e-15, -1.98935313e-15,  5.66415803e-16, -6.53102017e-16,\n",
       "       -9.67537162e-17, -1.06182618e-15,  7.31630312e-16, -8.17186319e-16,\n",
       "        1.17837740e-15,  1.38239642e-15,  8.42337311e-16, -7.39326378e-16,\n",
       "       -6.85529411e-16, -1.46602730e-15,  5.74535974e-16, -1.84225968e-15,\n",
       "        1.22780786e-15, -4.60879113e-16,  1.19361632e-15,  2.86535240e-16,\n",
       "        9.62385727e-16,  1.64419589e-16,  1.21228805e-15,  1.11285647e-15,\n",
       "       -4.72681894e-16, -1.38143719e-15, -4.10032674e-15,  5.58657565e-16,\n",
       "        6.58195720e-16, -2.35502506e-15, -2.87945223e-16,  5.56732438e-16,\n",
       "        8.97104613e-16,  6.38427977e-15,  1.23118404e-15,  7.23738847e-16,\n",
       "       -2.47034615e-16, -4.90274488e-18, -1.04046771e-15,  9.98705563e-16,\n",
       "       -5.17786924e-16,  2.01687556e-16, -1.73276060e-15,  7.48778817e-16,\n",
       "        3.81792375e-16, -1.60817804e-15,  1.39002365e-15, -1.22469146e-15,\n",
       "        7.67157449e-16,  4.75444129e-16,  1.74609882e-15,  9.62523394e-16,\n",
       "       -2.01025641e-15,  5.29656319e-16, -2.51125343e-15, -1.89397387e-16,\n",
       "       -4.14903667e-16, -7.54230012e-16, -1.80813586e-15,  1.05190967e-15,\n",
       "        1.51519908e-15,  1.44666279e-15, -3.67261777e-16,  1.62605152e-15,\n",
       "       -6.69926337e-16,  5.15720799e-17,  5.64346347e-16, -1.64827929e-15,\n",
       "       -7.23796578e-16, -2.00879313e-16, -1.55557789e-16,  8.37641068e-17,\n",
       "        5.77036197e-16,  7.74333930e-16,  3.24629212e-15,  4.64439598e-16,\n",
       "        4.30380176e-16,  1.88178140e-15, -4.55038229e-16,  3.09205772e-15,\n",
       "       -1.42419410e-15,  6.39313047e-16, -1.20121135e-15,  1.95796712e-16,\n",
       "        1.26051614e-15,  1.36852751e-16, -3.82869292e-16,  2.21473950e-16,\n",
       "       -1.27358790e-15, -4.16287005e-16, -5.68209924e-15, -1.76946235e-15,\n",
       "        1.90158334e-15,  3.31832339e-16,  1.96584971e-16,  1.32619471e-15,\n",
       "       -1.03672626e-17, -7.81243958e-16, -1.02607478e-15,  5.90767435e-16,\n",
       "        8.58220162e-16, -8.40387759e-16, -2.28958408e-15,  1.14912968e-15,\n",
       "        6.69300171e-16,  3.89450694e-16,  1.91666238e-15,  8.94695429e-16,\n",
       "       -2.16034524e-15, -1.06986642e-15, -8.89555096e-16, -7.05824510e-15,\n",
       "        2.22373231e-16,  6.09214901e-16, -1.59909641e-15, -1.00092379e-15,\n",
       "       -1.21928023e-15,  9.96003280e-17,  7.98143773e-16, -3.20383720e-16,\n",
       "       -1.40320422e-15,  1.14073195e-16, -1.19245835e-15,  2.61661248e-15,\n",
       "       -8.59683436e-16, -3.36477513e-16, -2.88017499e-15,  2.33910669e-16,\n",
       "        1.45113699e-15, -2.22970531e-16,  2.81241697e-16, -2.71362044e-15,\n",
       "       -7.16167126e-16,  6.00761663e-16, -3.46194184e-16,  1.05916387e-15,\n",
       "        7.60058683e-18, -5.80957504e-16,  2.11162199e-16, -3.92901267e-16,\n",
       "       -1.05036202e-15, -9.42925737e-16,  4.96735986e-16,  1.31188393e-15,\n",
       "        4.62951899e-16, -4.57354155e-16, -8.15172374e-16,  1.19555033e-15,\n",
       "       -1.18713928e-15,  8.72425465e-16,  8.46549497e-16,  1.63259628e-15,\n",
       "       -1.65449876e-16, -2.32482922e-16,  1.44964041e-16,  1.12997389e-15,\n",
       "        1.16461063e-15,  1.87034832e-16,  7.58570984e-17, -1.59148028e-15,\n",
       "        7.08729742e-16,  7.64206476e-16, -1.33933753e-15, -1.16226140e-15,\n",
       "       -6.96385172e-16, -8.31721358e-16, -3.15669713e-16,  1.03204778e-15,\n",
       "       -4.48713067e-15, -4.47104576e-16,  3.51190188e-16,  3.81921161e-16,\n",
       "       -1.28529853e-15, -3.39968054e-16, -1.01660902e-15,  1.40057743e-15,\n",
       "        1.08048459e-15, -7.29267757e-16, -1.11944232e-15, -1.43718148e-15,\n",
       "       -1.12851506e-15, -4.92599295e-16,  1.50271129e-15,  9.46276391e-16,\n",
       "        1.09838361e-15, -3.72675224e-16,  1.04796172e-15, -1.79962933e-15,\n",
       "       -2.01878958e-15, -4.08428846e-16, -1.09208420e-15, -3.72324394e-17,\n",
       "        2.88049362e-15,  4.66591210e-16,  1.21038957e-15,  4.00370848e-16,\n",
       "        1.03633768e-15, -2.47162291e-16, -1.36179068e-15, -3.39087647e-15,\n",
       "       -1.63911551e-15,  1.75500503e-15, -1.33599798e-16, -1.18780541e-15,\n",
       "       -1.44243284e-15,  5.50011148e-16, -1.31851863e-15,  7.09172721e-16,\n",
       "       -1.79124271e-15, -2.01153538e-16,  1.93948191e-15,  1.78321136e-15,\n",
       "       -1.09379616e-15, -5.62214719e-16,  3.62199160e-17,  1.16454402e-15,\n",
       "        1.16975096e-15,  1.59313229e-15,  4.73725503e-16,  4.82356377e-16,\n",
       "       -1.00860875e-15, -7.86215537e-17, -7.57691687e-16,  2.27989627e-15,\n",
       "       -1.10584208e-15, -7.76596565e-16, -2.05278017e-16, -1.06781251e-17,\n",
       "        3.33555406e-16,  1.27129640e-15,  1.03743236e-15, -9.84470283e-16,\n",
       "        5.51031443e-16, -2.75259815e-16, -5.55548940e-16,  2.62147637e-15,\n",
       "       -7.65607577e-16, -1.97158623e-15, -4.40418813e-16, -1.62436731e-16,\n",
       "       -5.00013364e-16,  6.18908258e-16, -2.78237433e-16,  1.59463553e-16,\n",
       "       -8.10669309e-16,  1.59925406e-15,  5.38702416e-16, -5.32844879e-16,\n",
       "       -1.88827620e-15, -8.24982305e-16,  4.33963976e-17,  7.41338102e-16,\n",
       "       -1.50222057e-16, -7.35118633e-16,  1.90444549e-15,  8.11322121e-16,\n",
       "        2.63892241e-15, -1.85807814e-15,  1.31739064e-17,  1.01789688e-15,\n",
       "        1.46938017e-16, -1.82858173e-16, -4.24904556e-17, -3.92641475e-17,\n",
       "        1.36881395e-15, -2.50485854e-15,  2.39718911e-15, -2.73565615e-15,\n",
       "       -1.97735384e-15,  5.43547429e-16,  6.57525145e-16,  1.09538822e-15,\n",
       "       -4.48323600e-16, -1.66423320e-15,  1.08198006e-15, -1.68041359e-15,\n",
       "       -6.84352575e-16,  2.09742668e-15,  1.26732180e-15, -7.50137730e-16,\n",
       "       -2.24165908e-15, -1.26831878e-17,  3.83499899e-16, -1.08040021e-15,\n",
       "        1.06356257e-15,  1.33883127e-15,  1.00962794e-15,  7.48695550e-17,\n",
       "       -4.75559592e-16, -5.40136824e-16, -1.64961156e-15, -7.45425943e-16,\n",
       "        8.71835937e-17,  1.28401734e-15,  6.19442275e-16,  9.26689836e-16,\n",
       "       -1.34119160e-15,  3.41999762e-16,  6.82545132e-16,  9.48290335e-16,\n",
       "        2.41806575e-18,  1.18979049e-15, -1.00420117e-15, -1.25283561e-15,\n",
       "       -5.44246870e-16, -7.51200213e-16,  6.67814692e-16,  1.33583811e-15,\n",
       "       -7.16937620e-16,  1.02368780e-15, -1.58266955e-15, -1.04375619e-15,\n",
       "        9.05160391e-16,  4.12834211e-16, -9.05011621e-16, -1.73718817e-16,\n",
       "       -1.58068891e-15, -2.53648880e-15,  1.00627284e-15,  6.38162856e-16,\n",
       "        2.86599633e-16, -9.16777765e-17,  3.02535774e-17,  1.06917808e-16,\n",
       "        2.91735525e-16, -3.28341798e-16, -5.23738830e-16, -3.33812977e-16,\n",
       "       -1.21620491e-16, -2.52231569e-16, -7.31015248e-16,  1.37951872e-16,\n",
       "       -1.41607170e-15, -1.01416653e-15, -8.90023610e-16,  1.12805765e-15,\n",
       "       -3.14532844e-16, -1.22214683e-15, -1.01070485e-15, -1.15358390e-15,\n",
       "       -7.26041449e-16, -1.38249856e-15,  3.45347750e-15,  3.38922224e-16,\n",
       "        1.14007692e-15,  6.26778629e-16,  1.19417143e-15, -2.44956722e-15,\n",
       "        1.21798793e-15, -1.89707361e-15, -2.27687202e-15, -1.30718991e-15,\n",
       "        1.00311759e-15,  1.98766781e-15,  1.06439302e-15, -3.01040304e-16,\n",
       "        2.19589458e-15,  1.10560450e-15, -1.01798570e-15, -3.06977332e-15,\n",
       "       -8.22524271e-16, -2.59670063e-16,  1.25355282e-16,  7.04492020e-16,\n",
       "        1.13718812e-15,  2.80078183e-16,  1.64551039e-15, -2.18642882e-16,\n",
       "       -2.51466181e-15, -1.60172098e-15,  3.02755598e-15,  2.20903740e-15,\n",
       "       -1.09747988e-15, -1.59738889e-16,  8.49416093e-16, -4.29913882e-16,\n",
       "       -3.74734022e-15, -1.53650426e-16, -1.79010806e-15, -1.44925405e-15,\n",
       "       -5.49391643e-16, -1.12170162e-15, -5.60218538e-16,  3.29016814e-16,\n",
       "       -1.46159751e-15,  8.63301652e-16, -3.56308316e-16,  1.82002857e-15,\n",
       "        2.51065835e-15,  1.13661969e-15, -1.76380688e-15,  5.83815218e-16,\n",
       "       -5.17070831e-16, -5.21376275e-16, -1.93126404e-15,  9.69251346e-16,\n",
       "       -6.55966392e-16, -1.23568489e-15,  2.45599097e-15, -6.86774193e-15,\n",
       "        6.86500856e-16,  1.63287162e-16,  1.70159664e-15,  2.20597984e-15,\n",
       "        7.91411381e-16, -1.50042201e-16,  1.75524040e-16, -8.47142356e-16,\n",
       "        1.28497879e-15, -4.69668748e-16,  1.36204381e-16,  2.69030576e-15,\n",
       "       -7.01880776e-16,  3.12105897e-16,  9.38471523e-17, -1.47222234e-16,\n",
       "       -3.47037954e-15,  6.02902173e-16,  8.33608738e-16, -2.64663846e-16,\n",
       "        5.77219383e-16,  1.45618739e-15, -6.68601841e-16, -1.00374598e-15,\n",
       "        1.86462401e-15, -1.16314514e-15,  1.59730895e-15,  8.53344062e-16,\n",
       "        5.96656058e-16, -1.04442677e-15, -2.02925454e-16, -8.33786373e-16,\n",
       "        9.24011978e-16,  9.02002917e-16,  1.84334104e-15, -6.03073147e-17,\n",
       "       -1.03340447e-15, -2.83826296e-16, -7.58724195e-16,  2.95710123e-16,\n",
       "        1.08416609e-15, -1.03856035e-15, -1.77489801e-15, -1.05960574e-15,\n",
       "        1.73201453e-16, -6.54776233e-16, -9.27702359e-16, -5.81446002e-16,\n",
       "       -3.40424133e-15,  6.76334544e-16, -2.73867595e-16,  5.23097787e-15,\n",
       "       -2.44375631e-16, -2.24971375e-15,  3.12749826e-17,  4.53173055e-16,\n",
       "       -1.93089988e-16, -7.59179386e-16,  6.82813805e-16, -5.33706412e-16,\n",
       "       -4.21496171e-16,  4.49795756e-17,  1.16467946e-15, -5.82505155e-16,\n",
       "        1.09214859e-16,  2.23773444e-15, -2.71138667e-17, -7.70310482e-16,\n",
       "        4.18356461e-16, -9.36841715e-16,  1.44698586e-15,  1.06401998e-15,\n",
       "        1.04914522e-15, -2.58312260e-15,  7.55642215e-16, -3.10935722e-16,\n",
       "        9.71960290e-16,  2.33257857e-17, -3.64308583e-16,  2.78248535e-16,\n",
       "       -1.63141722e-15,  4.65323335e-16, -4.23623359e-16, -1.02115205e-15,\n",
       "       -6.86162238e-16, -4.75788298e-16,  9.35935773e-16,  9.26907440e-16,\n",
       "        7.00073333e-16,  3.79041243e-16,  7.58149099e-17, -1.67277303e-16,\n",
       "       -2.23763452e-15,  8.38360492e-16,  1.68302039e-15,  1.02019726e-15,\n",
       "        9.48963130e-17,  5.51179102e-16,  3.73008291e-16, -1.38488554e-15,\n",
       "        6.85924650e-16,  3.27184946e-16,  1.05352838e-15,  1.64939395e-15,\n",
       "        1.44929624e-15,  1.56511248e-15,  4.39790426e-16,  1.87741378e-15,\n",
       "       -1.51401114e-16,  2.72324163e-15, -1.42108547e-16,  2.35022668e-15,\n",
       "       -4.60822491e-16, -1.12226672e-15,  1.55883084e-15, -1.58177471e-15,\n",
       "       -2.27113661e-15, -8.98845443e-16, -7.07811587e-17, -2.01738626e-16,\n",
       "       -1.41635592e-16, -1.40502721e-15, -1.10293774e-15, -1.22237553e-15,\n",
       "       -1.43516310e-15, -6.65413280e-16,  4.86695129e-16,  1.13693499e-16,\n",
       "       -3.86939369e-16,  5.41815481e-16,  2.00647277e-15,  1.12564180e-15,\n",
       "        1.14408927e-15,  4.73781014e-16, -9.16053899e-16,  1.15497834e-15,\n",
       "        2.52118326e-16,  1.58177693e-15,  1.40292666e-15,  2.65411471e-15,\n",
       "        1.07579057e-15,  1.59550373e-15,  4.06761291e-16, -2.40285569e-16,\n",
       "        8.04534217e-17,  8.93869423e-16,  6.32200958e-16, -1.40735423e-15,\n",
       "        4.31885638e-16, -3.19140270e-16,  2.27768915e-16,  8.37019343e-16,\n",
       "       -5.26467758e-18,  1.48290269e-16,  2.39102071e-16,  1.58175029e-15,\n",
       "        1.61453517e-15,  2.45592435e-16, -9.89763826e-17,  2.20072849e-16,\n",
       "        2.73541190e-16, -3.11662252e-15,  1.16726406e-15,  2.93984836e-16,\n",
       "        3.19273497e-16,  1.36010758e-15, -2.82966983e-16, -1.18283827e-15,\n",
       "       -3.68651776e-16,  2.52614596e-15, -8.19756485e-16,  4.02665679e-16,\n",
       "       -6.64406308e-16, -1.80826687e-15, -9.33659816e-16, -1.17425181e-15,\n",
       "       -3.69859698e-16, -8.83602080e-16,  5.16653387e-17, -2.62442290e-16,\n",
       "       -2.40951703e-16,  2.25333086e-16, -3.49569262e-16,  5.58291191e-16,\n",
       "        1.95135019e-16, -1.39682488e-15, -1.25318422e-15, -2.10450768e-15,\n",
       "       -4.56377158e-16, -1.10947029e-15, -1.22301502e-15, -6.94431179e-16,\n",
       "        4.87022200e-15, -1.13918652e-15, -6.52899956e-17, -3.75317555e-16,\n",
       "        1.26277877e-15, -7.96785971e-16, -2.44031462e-16,  1.53110857e-16,\n",
       "       -2.63351119e-15,  3.94773103e-17, -4.45332660e-16, -7.33453298e-16,\n",
       "       -1.10809140e-16,  4.00213196e-17, -2.56380028e-15,  4.46653825e-16,\n",
       "        5.79485349e-16,  1.15952137e-15, -3.00082181e-17,  5.23761035e-16,\n",
       "       -9.05469033e-16,  5.40134604e-16, -1.23445476e-15, -2.01105799e-17,\n",
       "       -7.68722863e-16,  1.18407950e-15,  1.15985443e-15, -3.78974629e-16,\n",
       "       -1.32738043e-15,  3.47761819e-16, -3.97466504e-16, -1.50528034e-15,\n",
       "       -5.69277958e-16,  1.46389567e-15, -9.17048659e-16,  8.91813290e-16,\n",
       "        1.92474037e-15,  1.96540784e-15,  1.57257984e-15,  1.32247324e-15,\n",
       "        2.23163710e-16,  2.63908895e-16,  9.42645961e-16, -5.14754905e-17,\n",
       "        2.46147547e-15, -1.07784670e-15,  1.04528608e-15, -1.98841388e-15,\n",
       "        8.34052827e-16, -1.35315759e-15,  4.50237625e-16,  7.30793204e-16,\n",
       "       -4.65065764e-16, -7.37252481e-16,  4.61204408e-16, -2.71648704e-15,\n",
       "        1.02251541e-17,  6.07587314e-16,  1.12117204e-15,  1.64812608e-16,\n",
       "        1.48451917e-15,  1.54324997e-15, -5.17383913e-16,  1.51905155e-16,\n",
       "       -7.62190311e-16,  1.29079858e-15, -2.12947437e-16, -2.10176765e-15,\n",
       "        1.01697983e-15,  1.18683730e-15, -1.02718056e-15,  9.08508824e-16,\n",
       "        7.43349826e-16, -5.92113025e-16,  2.59320121e-15, -6.71107614e-16,\n",
       "        5.94624350e-16,  9.58246815e-16,  1.31591182e-15, -5.07902609e-16,\n",
       "       -2.17807772e-15, -6.39570619e-16, -1.09645626e-15, -6.44924114e-16,\n",
       "        3.87543331e-16,  4.54729587e-16, -6.00821615e-16, -7.77637954e-16,\n",
       "        1.28648203e-16, -5.05835374e-16, -3.03977954e-16, -1.07331033e-15])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"top_of_steps\"></div>\n",
    "# Steps\n",
    "1. <a href=\"#Implement-logistic-regression-likelihood.\">Implement logistic regression likelihood.</a>\n",
    "2. <a href=\"#Compute-derivative-of-logistic-regression.\">Compute derivative of logistic regression.</a>\n",
    "3. <a href=\"#Check-gradient.\">Check gradient.</a>\n",
    "4. <a href=\"#Tweak-gradient-ascent-code.\">Tweak gradient ascent code.</a>\n",
    "5. <a href=\"#Report-results-and-analysis.\">Report results and analysis.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement logistic regression likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is given as $D = {(\\mathbf{x}_i, y_i):, i = 1...n}$, where $y_i \\in \\{-1, +1\\}$, and $\\mathbf{x}_i \\in R^p$. In this case there are n samples and each sample has p features. <br \\>\n",
    "\n",
    "For logistic regression, \n",
    "* We have model parameters: $\\mathbf{w} \\in R^p$ for weight and a bias term $b$.\n",
    "* For a sample x and its label y, $p(y|\\mathbf{x}, \\mathbf{w}, b) = \\frac{1}{1+exp\\{-y(\\mathbf{w} \\cdot \\mathbf{x} + b)\\}}$ \n",
    "* We can define $x' = \\begin{bmatrix} 1\\\\ x \\end{bmatrix}$, then $ \\mathbf{w}' =  \\begin{bmatrix} b\\\\ \\mathbf{w} \\end{bmatrix}$. Therefore the bias term is included in the weight vector. For notation brevity, we still use notations $x, \\mathbf{w}$ as $x', \\mathbf{w}'$. This can be implemented by numpy.concatenate function.\n",
    "* Hence the first entry of the vector $w'$ is bias term and the rest are feature weights. In the code you can use w[0] to access the bias term and w[1:] to access the feature weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#We help you do the concatenate, so the first feature becomes the  bias term\n",
    "train_data_pad = np.concatenate( ( np.ones((trainData.shape[0], 1)), trainData ), axis = 1 )\n",
    "test_data_pad = np.concatenate( ( np.ones((testData.shape[0], 1)), testData ), axis = 1 )\n",
    "valid_data_pad = np.concatenate( ( np.ones((validData.shape[0], 1)), validData ), axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-do: \n",
    "1. Given the data $D = {(\\mathbf{x}_i, y_i)} $, write down the likelihood function ($L(\\mathbf{w})$) of logistic regression. ** [1 pt] **\n",
    "2. Take $\\log$ of the likelihood function in (1), write down the log likelihood function. Hint: $\\log$ will not cancel $\\exp$. ** [1 pt] **\n",
    "3. Add  ridge penalty in the log likelihood function (Let the weight of ridge penalty be $\\alpha$). Hint: Do not include $w_0$ in the ridge term. ** [1 pt] **\n",
    "4. Write a function to compute regularized log likelihood ** [1 pt] **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $ L(\\mathbf{w}) = \\prod_{i=1}^N \\frac{1}{1 + exp\\{-y_i(\\mathbf{w} \\cdot \\mathbf{x_i} + \\beta_0\\} }$\n",
    "2. $ LL(\\mathbf{w}) = -\\sum_{i=1}^N \\log(1 + exp\\{-y_i(x^T_i w + \\beta_0)\\} $\n",
    "3. $ PLL(\\mathbf{w}) = -\\sum_i log(1 + exp\\{-y_i(x^T_i w + \\beta_0)\\})  - \\frac{\\alpha}{2}\\sum_{j=1}^{p} \\beta_j^2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def loglikelihood(w, X, y, alpha):\n",
    "    #compute loglikelihood for current w, b, given the data X, y\n",
    "    #w is a vector, b is a scalar, X is a n*p matrix and y is a vector.\n",
    "    tmp = 1. + np.exp(-y * (np.dot(X, w)))\n",
    "    return -np.sum(np.log(tmp)) - (alpha / 2.) * np.sum(w[1:] ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1808712118395306\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "np.random.seed(1)\n",
    "X = np.random.randn(2,3)\n",
    "y = np.array([1,-1])\n",
    "w = np.ones(3)\n",
    "w[[1]] = -1;\n",
    "print(loglikelihood(w, X, y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.70793003, -4.23991495])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-y * np.dot(X, w)\n",
    "#X[1,0]-X[1,1]+X[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6243453636632417 0.6117564136500754 -0.5281717522634557\n",
      "-1.1808712118395306\n"
     ]
    }
   ],
   "source": [
    "#the values printed in this cell should be the same as the value printed in the previous cell.\n",
    "print(X[0,0], -X[0,1], X[0,2])\n",
    "print( -np.log(1+np.exp(-1*(X[0,0]-X[0,1]+X[0,2]))) - np.log(1+np.exp(1*(X[1,0]-X[1,1]+X[1,2]))) -1/2.*np.sum(w[1:]**2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top_of_steps\">top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute derivative of logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to optimize the function, we want to take the derivative of the function, and update $\\mathbf{w}$ according to the direction of the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-do:\n",
    "1. Write down the derivative of the **penalized log likelihood function** for each $ w_j $. Hint: Remember that bias term is $w_0$ and treat it separately from the rest of $w_j$, $j\\in\\{1,...,p\\}$ ** [1 pt] **\n",
    "2. Write down the gradient of log likelihood function. Hint: You can express this in terms of probabilities. ** [1 pt] **\n",
    "3. Update the loglikelihood function to return both the loglikelihood and the gradient. ** [1 pt] **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  \n",
    "$ \\frac{\\partial PLL(\\mathbf{w})}{ \\partial w_0} = \\sum_i \\frac{y_i exp\\{-y_i(x^T_i w + \\beta_0)\\}}{1 + exp\\{-y_i(x^T_i w + \\beta_0)\\}}$  \n",
    "$ \\frac{\\partial PLL(\\mathbf{w})}{ \\partial w_j} = \\sum_i \\frac{y_i x_{i,j} exp\\{-y_i(x^T_i w + \\beta_0)\\}}{1 + exp\\{-y_i(x^T_i w + \\beta_0)\\}}  - \\alpha \\beta_j, j>0$  \n",
    "  \n",
    "2.  \n",
    "$ \\nabla PLL(\\mathbf{w}) = \\sum_i ...y_i\\begin{bmatrix}  \\\\ \\\\ \\vdots \\\\  \\end{bmatrix} - \\begin{bmatrix}  \\\\  \\\\ \\vdots \\\\  \\end{bmatrix} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def loglikelihood(w, X, y, alpha): \n",
    "    #compute loglikelihood for current w, b, given the data X, y\n",
    "    #w is a vector, b is a scalar, X is a n*p matrix and y is a vector.\n",
    "    tmp = 1. + np.exp(-y * (np.dot(X, w)))\n",
    "    prob = 1./tmp\n",
    "    #print(f\"y: {(y).shape}\\nprob: {prob.shape}\\nexp: {np.exp(-y * (np.dot(X, w))).shape}\")\n",
    "    X = X.T #X becomes a p*n matrix so the gradVal can be compute straight-forwardly.\n",
    "    gradVal = np.dot(X, (y * prob) * (tmp - 1))\n",
    "    penalty = alpha/2.*np.sum(w[1:] ** 2)\n",
    "    gradPenalty = -alpha * w\n",
    "    gradPenalty[0] = 0;\n",
    "    return -np.sum( np.log( tmp ) ) - penalty, gradVal + gradPenalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=train_data_pad[:,:15]\n",
    "y=trainLabel\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (10000,15) and (3,) not aligned: 15 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-261-4b7a759d3b09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (10000,15) and (3,) not aligned: 15 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "np.exp(-y * (np.dot(X, w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top_of_steps\">top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very important we know the derivative we computed is correct. We can check it by comparing it with numerical answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load grad_check.py\n",
    "def grad_check(f,xy0,delta=1e-6,tolerance=1e-7):\n",
    "    f0,g0 = f(xy0)\n",
    "    p = len(xy0)\n",
    "    finite_diff = np.zeros(p)\n",
    "    gradient_correct = True\n",
    "    for i in range(p):\n",
    "        xy1 = np.copy(xy0)\n",
    "        xy2 = np.copy(xy0)\n",
    "        xy1[i] = xy1[i] - 0.5*delta\n",
    "        xy2[i] = xy2[i] + 0.5*delta\n",
    "        f1,_ = f(xy1)\n",
    "        f2,_ = f(xy2)\n",
    "        finite_diff = (f2 - f1)/(delta)\n",
    "        if (abs(finite_diff - g0[i])>tolerance):\n",
    "            print(\"Broken partial\",i,\" Finite Diff: \",finite_diff,\" Partial: \",g0[i])\n",
    "            gradient_correct = False\n",
    "    return gradient_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We initialize the w vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = np.random.randn( train_data_pad.shape[1] )*0.001\n",
    "w_init[0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-do:\n",
    "* Here is the code to test if your gradient computation is correct (If the result is true, you get **1 pt**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = lambda xy0: loglikelihood(xy0, X=train_data_pad[:,:15], y=trainLabel, alpha=1)\n",
    "grad_check( g, w_init[:15], delta=1e-6, tolerance=1e-5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top_of_steps\">top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweak gradient ascent code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we provide the gradient ascent function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# %load gradient_ascent\n",
    "def gradient_ascent(f,x,init_step,iterations):  \n",
    "    f_val,grad = f(x)                           # compute function value and gradient \n",
    "    f_vals = [f_val]\n",
    "    for it in range(iterations):                # iterate for a fixed number of iterations\n",
    "        #print 'iteration %d' % it\n",
    "        done = False                            # initial condition for done\n",
    "        line_search_it = 0                      # how many times we tried to shrink the step\n",
    "        step = init_step                        # reset step size to the initial size\n",
    "        while not done and line_search_it<100:  # are we done yet?\n",
    "            new_x = x + step*grad               # take a step along the gradient\n",
    "            new_f_val,new_grad = f(new_x)       # evaluate function value and gradient\n",
    "            if new_f_val<f_val:                 # did we go too far?\n",
    "                step = step*0.95                # if so, shrink the step-size\n",
    "                line_search_it += 1             # how many times did we shrank the step\n",
    "            else:\n",
    "                done = True                     # better than the last x, so we move on\n",
    "        \n",
    "        if not done:                            # did not find right step size\n",
    "            print(\"Line Search failed.\")\n",
    "        else:\n",
    "            f_val = new_f_val                   # ah, we are ok, accept the new x\n",
    "            x = new_x\n",
    "            grad = new_grad\n",
    "            f_vals.append(f_val)\n",
    "        plt.plot(f_vals)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Function value')\n",
    "    return f_val, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "w_init = np.random.randn( train_data_pad.shape[1] )*0.001\n",
    "w_init[0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-do:\n",
    "* Try different init_step (1e-4, 1e-5, 1e-6) using the following code, report the final regularized log-likelihood values. **[1 pt]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizeFn( init_step, iterations, alpha, w):\n",
    "    g = lambda xy0: loglikelihood(xy0, train_data_pad, trainLabel, alpha)\n",
    "    f_val, update_w = gradient_ascent( g, w, init_step, iterations )\n",
    "    return f_val, update_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for value: 0\n",
      "Time elapsed (seconds): 2.5561587810516357\n",
      "final log-likelihood = -2602.170368\n",
      "\n",
      "Calculating for value: 0\n",
      "Time elapsed (seconds): 2.065248966217041\n",
      "final log-likelihood = -3033.038249\n",
      "\n",
      "Calculating for value: 0\n",
      "Time elapsed (seconds): 2.217799425125122\n",
      "final log-likelihood = -4707.155301\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inits = [1e-4, 1e-5, 1e-6]\n",
    "for v in inits:  \n",
    "    print('Calculating for value: %d' % v)\n",
    "    start = time.time()\n",
    "    f_val, update_w=optimizeFn( init_step = v, iterations=100, alpha=0, w = w_init) #set init_step to 1e-4, 1e-5, 1e-6\n",
    "    end = time.time()\n",
    "    print('Time elapsed (seconds):', end-start)\n",
    "    print('final log-likelihood = %f\\n' % (f_val))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Final regularized log-likelihood values for (1e-4, 1e-5, 1e-6) are:\n",
    "1e-4: -2602.17\n",
    "1e-5: -3033.04\n",
    "1e-5: -4707.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top_of_steps\">top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report results and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the results, we need to have a prediction function, that uses the model we trained to predict the comment is positive and negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-do:\n",
    "1. Implement the prediction function. It should take as inputs feature weights and feature matrix. It should return vector of labels. **[1 pt]**\n",
    "2. Try different alpha (1000, 2000, 3000), and report which alpha produces the model that has the best accuracy on the validation set **[1 pt]**\n",
    "2. **[optional]** Report one sample that is classified wrong with high probabilites (> 90%). **[1 pt]**\n",
    "3. **[optional]** Report the words (entries in vocab_list associated with that feature) that cause the sample reported in (2) classify wrong. Note that weight w[i] correponds to word vocab_list[i-1], because we included bias term in w.**[1 pt]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(w, validData ):\n",
    "    prob = 1./(1+np.exp(... ) );\n",
    "    res = np.zeros(validData.shape[0])\n",
    "    res[prob>=...] = ...\n",
    "    res[prob<...] = ...\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#see the accuracy on the validation set\n",
    "#when init_step=1e-5, the model has the best accuracy in the validation set\n",
    "f_val, update_w=optimizeFn( init_step = 1e-5, iterations=100, alpha=1000, w=w_init) #try different alphas [1000, 2000, 3000]\n",
    "pred = prediction(update_w, valid_data_pad)\n",
    "print( 'accuracy on the validation set {:.2f}%'.format( 100.*np.mean(pred==validLabel)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best alpha is ..., and the accuracy of this alpha is: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Report one sample (sample index in the validation data set) that is classified wrong with high probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_idx = np.nonzero( validLabel != pred )[0] #use this command to get the samples that are predicted wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#implement the function to compute probability\n",
    "def computeProb(w, validData ):\n",
    "    prob = 1./(1+np.exp(... ) )\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the samples that are classified wrong and with probabilites > 0.9\n",
    "probs = computeProb(update_w, valid_data_pad)\n",
    "wrong_idx_high = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample index is ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Report the words that cause the sample reported in (2) classify wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use this function to get the most important words for each sample index\n",
    "#This function returns a list of top 10 words that influence the prediction.\n",
    "def getMostImportantFeatures( sampleIdx, validData, update_w, vocab_list ):\n",
    "    confusedList = []\n",
    "    intensity = validData[sampleIdx,:]*update_w\n",
    "    tmp = np.argsort( np.abs(intensity[0,:]) )[::-1]\n",
    "    for j in np.arange(10):\n",
    "        confusedList.append(vocab_list[tmp[j]-1])\n",
    "    return confusedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusedList = getMostImportantFeatures( sampleIdx, valid_data_pad, update_w, vocab_list) #use the sample index got from the previous result\n",
    "confusedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load file ids\n",
    "if not os.path.isfile('train_id.pgz'):\n",
    "    U.urlretrieve( \"https://sakai.unc.edu/access/content/group/c4f84923-328b-429b-a8dc-a340b0284e41/HW1/train_id.pgz\", \"train_id.pgz\" );\n",
    "train_id = pickle.load( gzip.open( \"train_id.pgz\", \"rb\" ) )\n",
    "valid_id = train_id[10000:15000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Retrieve the whole review and check if it is hard to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = valid_id[100]\n",
    "fileUrl = \"https://wwwx.cs.unc.edu/Courses/comp755-f18/hw1/reviews/\" + fileName + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('731_9', <http.client.HTTPMessage at 0x10668e780>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.urlretrieve(fileUrl, fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a href=\"#top_of_steps\">top</a>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
